{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeftEval_NLP_LSTM_Different_Approaches.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bq9lHSkdK6_",
        "colab_type": "code",
        "outputId": "7cb1ee4e-c4ff-4a68-d93e-bd4c5d0e5f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/adobe-research/deft_corpus.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deft_corpus'...\n",
            "remote: Enumerating objects: 894, done.\u001b[K\n",
            "remote: Counting objects: 100% (894/894), done.\u001b[K\n",
            "remote: Compressing objects: 100% (462/462), done.\u001b[K\n",
            "remote: Total 2196 (delta 601), reused 669 (delta 424), pack-reused 1302\u001b[K\n",
            "Receiving objects: 100% (2196/2196), 42.39 MiB | 5.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1386/1386), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvLVZxy2d4d-",
        "colab_type": "code",
        "outputId": "353d5913-9ccf-4ef3-9632-8fd276582e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!unzip src.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  src.zip\n",
            "   creating: scripts/\n",
            "  inflating: scripts/__init__.py     \n",
            "  inflating: scripts/task1_converter.py  \n",
            "   creating: source/\n",
            "  inflating: source/__init__.py      \n",
            "  inflating: source/classifiers.py   \n",
            "  inflating: source/data_loader.py   \n",
            "  inflating: source/text_vectorizers.py  \n",
            "  inflating: Data Loading and Preparation.ipynb  \n",
            "  inflating: README.md               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LkHO3wvMjR",
        "colab_type": "text"
      },
      "source": [
        "# Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_bdcSWpuDXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from source.data_loader import DeftCorpusLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H8lHo7Nuc9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DeftCorpusLoader('deft_corpus/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL8Px4_Av_ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, dev_df = loader.load_classification_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxg-OVsxwJnC",
        "colab_type": "code",
        "outputId": "22e0ce11-b529-4952-e31d-52087f11e754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>HasDef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6110 . Defining obscenity has been something ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Into the early twentieth century , written wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1973 , the Supreme Court established the M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Miller v. California , 413 U.S. 15 ( 1973 ) .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>However , the application of this standard ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  HasDef\n",
              "0   6110 . Defining obscenity has been something ...       0\n",
              "1   Into the early twentieth century , written wo...       0\n",
              "2   In 1973 , the Supreme Court established the M...       1\n",
              "3      Miller v. California , 413 U.S. 15 ( 1973 ) .       0\n",
              "4   However , the application of this standard ha...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t5z25TAvU3E",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjeLWvpkwjPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, GlobalMaxPooling1D, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eEBFWkKvYSk",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYJWephNww7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.preprocess_data(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nr2VnhzBmY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.clean_data(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sK8oxFhHJNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.preprocess_data(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0aOHHhTBm8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.clean_data(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PImKzQV5hhK_",
        "colab_type": "code",
        "outputId": "df1822a1-3475-45cd-e41b-c267343bcead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>HasDef</th>\n",
              "      <th>Parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6110 . Defining obscenity has been something ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[defining, obscenity, challenge, court, suprem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Into the early twentieth century , written wo...</td>\n",
              "      <td>0</td>\n",
              "      <td>[early, 20, century, write, work, frequently, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1973 , the Supreme Court established the M...</td>\n",
              "      <td>1</td>\n",
              "      <td>[supreme, court, establish, miller, test, deci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In particular , the concept of “ contemporary...</td>\n",
              "      <td>0</td>\n",
              "      <td>[particular, concept, contemporary, community,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6113 . Free expression includes the right to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[free, expression, include, right, assemble, p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                             Parsed\n",
              "0   6110 . Defining obscenity has been something ...  ...  [defining, obscenity, challenge, court, suprem...\n",
              "1   Into the early twentieth century , written wo...  ...  [early, 20, century, write, work, frequently, ...\n",
              "2   In 1973 , the Supreme Court established the M...  ...  [supreme, court, establish, miller, test, deci...\n",
              "5   In particular , the concept of “ contemporary...  ...  [particular, concept, contemporary, community,...\n",
              "6   6113 . Free expression includes the right to ...  ...  [free, expression, include, right, assemble, p...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJOBTaUhGXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = np.unique([y for x in train_df['Parsed'] for y in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jpJywWg-a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3wDmyfGuQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = np.max([np.count_nonzero(x) for x in train_df['Parsed']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4M4v73iUe_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_length = int(np.ceil(np.average([np.count_nonzero(x) for x in train_df['Parsed']])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFCQPp5fqRM",
        "colab_type": "code",
        "outputId": "90b22798-febe-4267-e68e-f0ab142595af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df['HasDef'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxBb6jrpfe8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_positive_class_length = np.count_nonzero([x for x in train_df['HasDef'] if x == 1])\n",
        "train_negative_class_length = np.abs(len(train_df['HasDef']) - train_positive_class_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4V7dTTfuA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = vocab_size    # max no. of words for tokenizer\n",
        "MAX_SEQUENCE_LENGTH = avg_length # max length of each entry (sentence), including padding\n",
        "EMBEDDING_DIM = 100      # embedding dimensions for word vectors (word2vec/GloVe)\n",
        "GLOVE_DIR = \"glove.6B.\"+str(EMBEDDING_DIM)+\"d.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAxMRTILv9ST",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbJaWG75J4rD",
        "colab_type": "text"
      },
      "source": [
        "Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture. A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. \n",
        "LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. \n",
        "Intuitively, the cell is responsible for keeping track of the dependencies between the elements in the input sequence. The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit. The activation function of the LSTM gates is often the logistic sigmoid function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hede02M2Knrv",
        "colab_type": "text"
      },
      "source": [
        "![LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZtbaocbYZFt",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing for Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-dq42hPMli-",
        "colab_type": "text"
      },
      "source": [
        "To use keras and make a model with an embedding layer as an input layer we need each word in the vocab to be represented by a number so the Tokenizer class is used. The input, also, has to be a vector of numbers and that vector has to be of the same size for all the documents. The average length is taken and extra words are removed form the vectors and padding is used if the length is less than the average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd1D2iwqDK5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oh0aUvDF8uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(train_df['Parsed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL6YtbxeFLZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_df['Parsed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ggADNEwjFT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE8kPLutGktk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trunc_type = 'post'\n",
        "padding_type = 'post'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5tiZl-LFPL9",
        "colab_type": "code",
        "outputId": "0c4521ee-abec-4903-8e96-77036c73fcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_padded = pad_sequences(train_sequences, maxlen=avg_length, padding=padding_type, truncating=trunc_type)\n",
        "print(len(train_sequences[0]))\n",
        "print(len(train_padded[0]))\n",
        "\n",
        "print(len(train_sequences[1]))\n",
        "print(len(train_padded[1]))\n",
        "\n",
        "print(len(train_sequences[10]))\n",
        "print(len(train_padded[10]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "13\n",
            "24\n",
            "13\n",
            "18\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av9vxUqtFaMt",
        "colab_type": "code",
        "outputId": "fdb60a8f-6e4e-42a4-8323-b170ad4893c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_padded[10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 756 2521  145   17   20   22  573 1134  114   19  648   24   27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqVaGsUrHy4N",
        "colab_type": "code",
        "outputId": "ceaaa562-39b9-4c77-dd48-f0d2c817996c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dev_sequences = tokenizer.texts_to_sequences(dev_df['Parsed'])\n",
        "dev_padded = pad_sequences(dev_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "print(len(dev_sequences))\n",
        "print(dev_padded.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "780\n",
            "(780, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_aC1cmYecU",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgCM8moPOKgr",
        "colab_type": "text"
      },
      "source": [
        "The first approach to use with the LSTM is Word2Vec. It's used as the pretrained, freezed embeddings to the embeddings layer. Firstly, the word2vec continous bag of words model is trained on the train dataset. The embeddings of the dataset's vocab are added to the embedding layer and freezed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUZciIFs3LQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(size=100, min_count=2, window=5, iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwZgKNUwygPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model.build_vocab(train_df['Parsed'])\n",
        "w2v_model.train(train_df['Parsed'], total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)\n",
        "w2v_model.wv.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ljiCY3uEOUB",
        "colab_type": "code",
        "outputId": "f9a1d9c3-2fd8-4029-80a3-bf95b3e4ff07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "w2v_model.wv.syn0.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10102, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STZ5_mh4yxJ9",
        "colab_type": "code",
        "outputId": "5f837f7e-d040-46aa-f3bf-37cb70997e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "w2v_pretrained_weights = w2v_model.wv.syn0\n",
        "\n",
        "vocab_size, emdedding_size = w2v_pretrained_weights.shape\n",
        "\n",
        "print('Result embedding shape:', w2v_pretrained_weights.shape)\n",
        "\n",
        "print('Checking similar words:')\n",
        "\n",
        "for word in ['model', 'network', 'train', 'learn']:\n",
        "\n",
        "  most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in w2v_model.most_similar(word)[:8])\n",
        "\n",
        "  print('  %s -> %s' % (word, most_similar))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result embedding shape: (10102, 100)\n",
            "Checking similar words:\n",
            "  model -> bohr (0.45), informational (0.44), concept (0.43), economics (0.41), planetary (0.41), algorithm (0.40), acquisitive (0.39), rendition (0.38)\n",
            "  network -> adenohypophysis (0.53), capillary (0.48), peritubular (0.48), buren (0.43), infundibulum (0.43), gyrus (0.42), mantle (0.42), anchor (0.41)\n",
            "  train -> persuade (0.45), rebel (0.44), postdoctoral (0.43), volunteer (0.42), toilet (0.41), weaponry (0.41), nurse (0.41), online (0.41)\n",
            "  learn -> associative (0.53), habituation (0.49), earlier (0.48), helplessness (0.47), powerless (0.46), tolman (0.45), thought (0.45), biopsychology (0.44)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjocY3i_3IS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2idx(word):\n",
        "  return word_model.wv.vocab[word].index\n",
        "\n",
        "def idx2word(idx):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKfjKUdvZS13",
        "colab_type": "text"
      },
      "source": [
        "## Glove Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZCpxtJRQ5XJ",
        "colab_type": "text"
      },
      "source": [
        "The second approach used with LSTM is using Glove's embeddings as the fixed embeddings of the embeddings layer.GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. The network is used with freezing the weights and with training them to experiment on the different results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZrTOsIPcPUv",
        "colab_type": "code",
        "outputId": "e51004a3-9e9b-4d3d-88b8-4bdcb9ff96b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-17 19:17:07--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-17 19:17:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-17 19:17:08--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.26MB/s    in 6m 29s  \n",
            "\n",
            "2020-01-17 19:23:37 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouGGyOopcS-L",
        "colab_type": "code",
        "outputId": "8c316892-5a8a-4749-cab4-f951cabe6419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef0AdzRzkqj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word, i = zip(*word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R5unj65e6vW",
        "colab_type": "code",
        "outputId": "0dbf6216-ce2b-4758-ee3a-7cf398d60f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open(GLOVE_DIR)\n",
        "print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
        "f.close()\n",
        "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
        "\n",
        "glove_embedding_matrix = np.random.random((len(word_index), EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        glove_embedding_matrix[i-1] = embedding_vector\n",
        "print(\" Completed!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe from: glove.6B.100d.txt ...Done.\n",
            " Proceeding with Embedding Matrix... Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32V7mKjbwEAE",
        "colab_type": "text"
      },
      "source": [
        "## Model Defintition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCXqF5_z3diR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lstm_embeddings_model(weights=[], weights_trainable=False):\n",
        "  model = Sequential()\n",
        "  if weights != []:\n",
        "    weights = [weights]\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, weights=weights, trainable=weights_trainable))\n",
        "  model.add(Bidirectional(LSTM(units=EMBEDDING_DIM)))\n",
        "  model.add(Dense(vocab_size, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOOw-a8h5nMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_index = int(len(dev_padded)/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCYcYE7YYj-E",
        "colab_type": "text"
      },
      "source": [
        "## Training Using Our Word2Vec Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wVhExjmIDoq",
        "colab_type": "code",
        "outputId": "68865c89-ee34-4b67-ca02-2e79ff2384e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "num_epochs = 3\n",
        "word2VecLSTMModel = get_lstm_embeddings_model(w2v_pretrained_weights, True)\n",
        "history = word2VecLSTMModel.fit(train_padded, train_df['HasDef'].values, epochs=num_epochs, validation_data=(dev_padded[:validation_index], dev_df['HasDef'].values[:validation_index]), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 16165 samples, validate on 390 samples\n",
            "Epoch 1/3\n",
            "16165/16165 - 21s - loss: 0.5794 - acc: 0.6993 - val_loss: 0.5235 - val_acc: 0.7590\n",
            "Epoch 2/3\n",
            "16165/16165 - 19s - loss: 0.4357 - acc: 0.8002 - val_loss: 0.5617 - val_acc: 0.7000\n",
            "Epoch 3/3\n",
            "16165/16165 - 20s - loss: 0.2923 - acc: 0.8767 - val_loss: 0.6748 - val_acc: 0.7051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xovhoEgHQDR",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GLkA4_UHTlA",
        "colab_type": "code",
        "outputId": "61d88173-0ffa-458a-e4dd-8a7a550c08d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted_labels_word2vec_lstm = [1 if x>0.5 else 0 for x in word2VecLSTMModel.predict(dev_padded[validation_index:])]\n",
        "print('Dev classification report:\\n {}'.format(classification_report(dev_df['HasDef'].values[validation_index:], predicted_labels_word2vec_lstm)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.88      0.79       239\n",
            "           1       0.70      0.42      0.53       151\n",
            "\n",
            "    accuracy                           0.71       390\n",
            "   macro avg       0.70      0.65      0.66       390\n",
            "weighted avg       0.70      0.71      0.69       390\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALoWP6KmYVq",
        "colab_type": "text"
      },
      "source": [
        "## Training Using Glove 6B 100 Dim Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6sLIeR_-xpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8RXHfqsFWnF",
        "colab_type": "text"
      },
      "source": [
        "### Trainable Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JowSGTDFTsF",
        "colab_type": "code",
        "outputId": "98126fab-1402-4b9b-f6d4-7eafee648b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "num_epochs = 3\n",
        "glove_lstm_trainable_weights_model = get_lstm_embeddings_model(glove_embedding_matrix, True)\n",
        "history = glove_lstm_trainable_weights_model.fit(train_padded, train_df['HasDef'].values, epochs=num_epochs, validation_data=(dev_padded[:validation_index], dev_df['HasDef'].values[:validation_index]), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 16165 samples, validate on 390 samples\n",
            "Epoch 1/3\n",
            "16165/16165 - 22s - loss: 0.6021 - acc: 0.6864 - val_loss: 0.5650 - val_acc: 0.7000\n",
            "Epoch 2/3\n",
            "16165/16165 - 20s - loss: 0.4949 - acc: 0.7613 - val_loss: 0.9451 - val_acc: 0.6923\n",
            "Epoch 3/3\n",
            "16165/16165 - 20s - loss: 0.3645 - acc: 0.8387 - val_loss: 0.7191 - val_acc: 0.7359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GFfhNCvYBTLg"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b0ec0c48-9874-475b-9115-5abcff031fe8",
        "id": "gTg0U25TBTLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted_labels_glove_lstm = [1 if x>0.5 else 0 for x in glove_lstm_trainable_weights_model.predict(dev_padded[validation_index:])]\n",
        "print('Dev classification report:\\n {}'.format(classification_report(dev_df['HasDef'].values[validation_index:], predicted_labels_glove_lstm)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.96      0.78       239\n",
            "           1       0.77      0.23      0.35       151\n",
            "\n",
            "    accuracy                           0.67       390\n",
            "   macro avg       0.72      0.59      0.57       390\n",
            "weighted avg       0.70      0.67      0.61       390\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLYQAQc5FdbV",
        "colab_type": "text"
      },
      "source": [
        "### Non Trainable Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlJcxCzcIa4a",
        "colab_type": "code",
        "outputId": "1234daca-df4d-41e2-b0c3-6bad8c4724c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "num_epochs = 3\n",
        "glove_lstm_freezed_weights_model = get_lstm_embeddings_model(glove_embedding_matrix, False)\n",
        "history = glove_lstm_freezed_weights_model.fit(train_padded, train_df['HasDef'].values, epochs=num_epochs, validation_data=(dev_padded[:validation_index], dev_df['HasDef'].values[:validation_index]), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 16165 samples, validate on 390 samples\n",
            "Epoch 1/3\n",
            "16165/16165 - 20s - loss: 0.6222 - acc: 0.6617 - val_loss: 0.5924 - val_acc: 0.6949\n",
            "Epoch 2/3\n",
            "16165/16165 - 17s - loss: 0.5922 - acc: 0.6889 - val_loss: 0.5981 - val_acc: 0.7077\n",
            "Epoch 3/3\n",
            "16165/16165 - 17s - loss: 0.5457 - acc: 0.7280 - val_loss: 0.5753 - val_acc: 0.7256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VEmL-pFXFrS2"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c4f3a183-6e0c-4e8c-abd0-01ddbe22c629",
        "id": "dbBh6TbSFrTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted_labels_glove_lstm_freezed_weights = [1 if x>0.5 else 0 for x in glove_lstm_freezed_weights_model.predict(dev_padded[validation_index:])]\n",
        "print('Dev classification report:\\n {}'.format(classification_report(dev_df['HasDef'].values[validation_index:], predicted_labels_glove_lstm_freezed_weights)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.92      0.76       239\n",
            "           1       0.61      0.21      0.31       151\n",
            "\n",
            "    accuracy                           0.64       390\n",
            "   macro avg       0.63      0.56      0.53       390\n",
            "weighted avg       0.63      0.64      0.58       390\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}