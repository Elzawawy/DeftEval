{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation\n",
    "In this notebook we show: \n",
    "- How to use our data loader implementation specifically built for the DeftCorpus dataset ?\n",
    "- How we prepared the DeftCorpus dataset for usage for Sentence Definition Classification ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports cell\n",
    "from source.data_loader import DeftCorpusLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset for classification using DeftCorpusLoader\n",
    "\n",
    "Possible Steps for Class Usages:\n",
    "\n",
    "- Create instance of the class, with the path to your **\"data\" folder** from \"deft_corpus\" folder.\n",
    "\n",
    "\n",
    "- Call `load_classification_data` on class instance with **no arguments passed**, this will create two folders in \"deft_files\" folder by default including the re-formatted for classification task. Then will load these files and return two dataframes. The two dataframes include two splits, a training split and a development split (used for testing purposes during Training phase of Competition)\n",
    "\n",
    "\n",
    "- Alternatively, you can call `convert_to_classififcation_format` on class instance with **no arguments passed or pass arguments to specify folders and not use defaults** to first convert and create the two folders. The, call `load_classification_data` with the folders paths created from by the first method. This alternative way is provided for those who intend to work with **their own folder paths rather than the provided defaults.**\n",
    "\n",
    "*In this notebook, we use the rather easier and preferred method one.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deft_loader = DeftCorpusLoader(\"deft_corpus/data\")\n",
    "trainframe, devframe = deft_loader.load_classification_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring dataset \n",
    "- There are two columns: `Sentence` which has the sentence text, `HasDef` boolean value to determine whether it is a definition or not. \n",
    "- There are **18,157 instances for training** and **865 instances for development** (testing purposes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of  train  Dataframe:\n",
      "==============================================================\n",
      "                                            Sentence  HasDef\n",
      "0   3918 . You may recall that 6 x 6 = 36 , 6 x 7...       0\n",
      "1   Memorizing these facts is rehearsal . Another...       1\n",
      "2   Chunking is useful when trying to remember in...       0\n",
      "3   3921 . Use elaborative rehearsal : In a famou...       1\n",
      "4      Their theory is called levels of processing .       0\n",
      "==============================================================\n",
      "Number of instances of  train is 18157\n",
      "\n",
      "Head of  dev  Dataframe:\n",
      "==============================================================\n",
      "                                            Sentence  HasDef\n",
      "0   309 . Both photosystems have the same basic s...       1\n",
      "1   Each photosystem is serviced by the light - h...       0\n",
      "2   The absorption of a single photon or distinct...       0\n",
      "3   390 . Mistakes in the duplication or distribu...       0\n",
      "4   To prevent a compromised cell from continuing...       0\n",
      "==============================================================\n",
      "Number of instances of  dev is 865\n"
     ]
    }
   ],
   "source": [
    "deft_loader.explore_data(trainframe, \"train\")\n",
    "deft_loader.explore_data(devframe, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring classes and classification problem\n",
    "- There are **12,143 instances** of class label `0` ---> `This sentence is not a definition`.\n",
    "- There are **6,014 instances** of class label `1` ---> `This sentence is a definition`.\n",
    "- Determining problem: **Binary Classification Problem.**\n",
    "- A clear **classes imbalance** case exists in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12143\n",
       "1     6014\n",
       "Name: HasDef, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainframe.HasDef.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dataset using Spacy\n",
    "- Tokenizing corpus sentences into word tokens.\n",
    "- Lemmatization of each token. \n",
    "- Lowercase each token. \n",
    "- Removing stop words, punctuations, spaces and non alphanumeric characters.\n",
    "- Adds a column on the dataframe for preprocessed tokens according to above rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deft_loader.preprocess_data(trainframe)\n",
    "trainframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
