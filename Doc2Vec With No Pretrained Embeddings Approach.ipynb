{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeftEval_NLP_Doc2Vec_No_Pretrained_Embeddings_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rZ2tl2GXv5Yn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bq9lHSkdK6_",
        "colab_type": "code",
        "outputId": "7cb1ee4e-c4ff-4a68-d93e-bd4c5d0e5f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/adobe-research/deft_corpus.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deft_corpus'...\n",
            "remote: Enumerating objects: 894, done.\u001b[K\n",
            "remote: Counting objects: 100% (894/894), done.\u001b[K\n",
            "remote: Compressing objects: 100% (462/462), done.\u001b[K\n",
            "remote: Total 2196 (delta 601), reused 669 (delta 424), pack-reused 1302\u001b[K\n",
            "Receiving objects: 100% (2196/2196), 42.39 MiB | 5.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1386/1386), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvLVZxy2d4d-",
        "colab_type": "code",
        "outputId": "353d5913-9ccf-4ef3-9632-8fd276582e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!unzip src.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  src.zip\n",
            "   creating: scripts/\n",
            "  inflating: scripts/__init__.py     \n",
            "  inflating: scripts/task1_converter.py  \n",
            "   creating: source/\n",
            "  inflating: source/__init__.py      \n",
            "  inflating: source/classifiers.py   \n",
            "  inflating: source/data_loader.py   \n",
            "  inflating: source/text_vectorizers.py  \n",
            "  inflating: Data Loading and Preparation.ipynb  \n",
            "  inflating: README.md               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LkHO3wvMjR",
        "colab_type": "text"
      },
      "source": [
        "# Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_bdcSWpuDXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from source.data_loader import DeftCorpusLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H8lHo7Nuc9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DeftCorpusLoader('deft_corpus/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL8Px4_Av_ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, dev_df = loader.load_classification_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxg-OVsxwJnC",
        "colab_type": "code",
        "outputId": "22e0ce11-b529-4952-e31d-52087f11e754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>HasDef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6110 . Defining obscenity has been something ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Into the early twentieth century , written wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1973 , the Supreme Court established the M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Miller v. California , 413 U.S. 15 ( 1973 ) .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>However , the application of this standard ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  HasDef\n",
              "0   6110 . Defining obscenity has been something ...       0\n",
              "1   Into the early twentieth century , written wo...       0\n",
              "2   In 1973 , the Supreme Court established the M...       1\n",
              "3      Miller v. California , 413 U.S. 15 ( 1973 ) .       0\n",
              "4   However , the application of this standard ha...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t5z25TAvU3E",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjeLWvpkwjPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, GlobalMaxPooling1D, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eEBFWkKvYSk",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYJWephNww7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.preprocess_data(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nr2VnhzBmY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.clean_data(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sK8oxFhHJNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.preprocess_data(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0aOHHhTBm8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader.clean_data(dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PImKzQV5hhK_",
        "colab_type": "code",
        "outputId": "df1822a1-3475-45cd-e41b-c267343bcead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>HasDef</th>\n",
              "      <th>Parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6110 . Defining obscenity has been something ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[defining, obscenity, challenge, court, suprem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Into the early twentieth century , written wo...</td>\n",
              "      <td>0</td>\n",
              "      <td>[early, 20, century, write, work, frequently, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1973 , the Supreme Court established the M...</td>\n",
              "      <td>1</td>\n",
              "      <td>[supreme, court, establish, miller, test, deci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In particular , the concept of “ contemporary...</td>\n",
              "      <td>0</td>\n",
              "      <td>[particular, concept, contemporary, community,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6113 . Free expression includes the right to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[free, expression, include, right, assemble, p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ...                                             Parsed\n",
              "0   6110 . Defining obscenity has been something ...  ...  [defining, obscenity, challenge, court, suprem...\n",
              "1   Into the early twentieth century , written wo...  ...  [early, 20, century, write, work, frequently, ...\n",
              "2   In 1973 , the Supreme Court established the M...  ...  [supreme, court, establish, miller, test, deci...\n",
              "5   In particular , the concept of “ contemporary...  ...  [particular, concept, contemporary, community,...\n",
              "6   6113 . Free expression includes the right to ...  ...  [free, expression, include, right, assemble, p...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJOBTaUhGXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = np.unique([y for x in train_df['Parsed'] for y in x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jpJywWg-a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3wDmyfGuQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = np.max([np.count_nonzero(x) for x in train_df['Parsed']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4M4v73iUe_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_length = int(np.ceil(np.average([np.count_nonzero(x) for x in train_df['Parsed']])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFCQPp5fqRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90b22798-febe-4267-e68e-f0ab142595af"
      },
      "source": [
        "len(train_df['HasDef'])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxBb6jrpfe8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_positive_class_length = np.count_nonzero([x for x in train_df['HasDef'] if x == 1])\n",
        "train_negative_class_length = np.abs(len(train_df['HasDef']) - train_positive_class_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4V7dTTfuA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = vocab_size    # max no. of words for tokenizer\n",
        "MAX_SEQUENCE_LENGTH = avg_length # max length of each entry (sentence), including padding\n",
        "EMBEDDING_DIM = 100      # embedding dimensions for word vectors (word2vec/GloVe)\n",
        "GLOVE_DIR = \"glove.6B.\"+str(EMBEDDING_DIM)+\"d.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ_AJOijvc_d",
        "colab_type": "text"
      },
      "source": [
        "# Doc2Vec Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOpkgAMDvpse",
        "colab_type": "text"
      },
      "source": [
        "## Buliding Vocab and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcT6GwmnyfZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tagged = train_df.apply(lambda x: TaggedDocument(words= x['Parsed'], tags= str(x['HasDef'])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN8THrwJHPG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_tagged = dev_df.apply(lambda x: TaggedDocument(words= x['Parsed'], tags= str(x['HasDef'])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2RwmBhYN_EH",
        "colab_type": "code",
        "outputId": "c1b3d44f-045f-4c29-9501-0b1ea19d4176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "train_tagged.values"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([TaggedDocument(words=['defining', 'obscenity', 'challenge', 'court', 'supreme', 'court', 'justice', 'potter', 'stewart', 'famously', 'say', 'obscenity', 'have', 'watch', 'pornography', 'supreme', 'court', 'build', 'know'], tags='0'),\n",
              "       TaggedDocument(words=['early', '20', 'century', 'write', 'work', 'frequently', 'ban', 'obscene', 'include', 'work', 'note', 'author', 'james', 'joyce', 'henry', 'miller', 'today', 'rare', 'court', 'uphold', 'obscenity', 'charge', 'write', 'material'], tags='0'),\n",
              "       TaggedDocument(words=['supreme', 'court', 'establish', 'miller', 'test', 'decide', 'obscene', 'average', 'person', 'apply', 'contemporary', 'community', 'standard', 'find', 'work', 'take', 'appeal', 'prurient', 'interest', 'b', 'work', 'depict', 'describe', 'patently', 'offensive', 'way', 'sexual', 'conduct', 'specifically', 'define', 'applicable', 'state', 'law', 'c', 'work', 'take', 'lack', 'literary', 'artistic', 'political', 'scientific', 'value'], tags='1'),\n",
              "       ...,\n",
              "       TaggedDocument(words=['free', 'electron', 'material', 'air', 'move', 'loose', 'sand'], tags='0'),\n",
              "       TaggedDocument(words=['substance', 'free', 'electron', 'allow', 'charge', 'relatively', 'freely', 'call', 'conductor'], tags='0'),\n",
              "       TaggedDocument(words=['electrostatic', 'repulsion', 'leave', 'charge', 'electroscope', 'separate'], tags='0')],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n7Io6aoy8tg",
        "colab_type": "code",
        "outputId": "f85239bf-301c-4cc0-e9be-0b217d82fe06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, epochs=30)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16165/16165 [00:00<00:00, 1645334.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmxbE_Dpgmu5",
        "colab_type": "code",
        "outputId": "b04e55ee-b548-4975-bff9-2cf3abad9de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065, epochs=30)\n",
        "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16165/16165 [00:00<00:00, 1604831.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l395uySq3uTZ",
        "colab_type": "code",
        "outputId": "132d51a7-3491-4999-dc9f-64a0d93fffb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=model_dbow.epochs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16165/16165 [00:00<00:00, 949858.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.9 s, sys: 6.86 s, total: 47.8 s\n",
            "Wall time: 30 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6nYmfdsithL",
        "colab_type": "code",
        "outputId": "c8048c6a-633e-42e1-bd73-204f5ac56f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=model_dmm.epochs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16165/16165 [00:00<00:00, 1290389.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMEp7ksa4O4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    labels, vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, epochs=model.epochs)) for doc in tagged_docs.values])\n",
        "    return labels, vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cnqyu6vIWTQ",
        "colab_type": "code",
        "outputId": "faef84c8-d10c-49a3-d786-caf88d477f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_tagged)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKvPVVvj5j8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_dbow, X_train_dbow = vec_for_learning(model_dbow, train_tagged)\n",
        "y_dev_dbow, X_dev_dbow = vec_for_learning(model_dbow, dev_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYS4pqO_kRkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_dmm, X_train_dmm = vec_for_learning(model_dmm, train_tagged)\n",
        "y_dev_dmm, X_dev_dmm = vec_for_learning(model_dmm, dev_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le2NX4vgvxSm",
        "colab_type": "text"
      },
      "source": [
        "## Infernece Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx0bfqiMv0Oy",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7CmRg3yFSZw",
        "colab_type": "code",
        "outputId": "f4b6ee06-514e-4997-a117-e577f05bd9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_dbow, y_train_dbow)\n",
        "\n",
        "y_pred_dbow = nb.predict(X_dev_dbow)\n",
        "\n",
        "print('Dev Classification Report:\\n {}'.format(classification_report(y_dev_dbow, y_pred_dbow)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78       509\n",
            "           1       0.59      0.64      0.61       271\n",
            "\n",
            "    accuracy                           0.72       780\n",
            "   macro avg       0.69      0.70      0.70       780\n",
            "weighted avg       0.73      0.72      0.72       780\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxsPgEWgv3Kf",
        "colab_type": "text"
      },
      "source": [
        "### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl0ORl74NUsD",
        "colab_type": "code",
        "outputId": "3c2894c8-34b0-4dd5-fa7f-f5f335ad1917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "svc = LinearSVC(class_weight='balanced')\n",
        "svc.fit(X_train_dbow, y_train_dbow)\n",
        "y_pred_dbow_svc = svc.predict(X_dev_dbow)\n",
        "\n",
        "\n",
        "print('Dev accuracy %s' % accuracy_score(y_dev_dbow, y_pred_dbow_svc))\n",
        "print('Dev classification report:\\n {}'.format(classification_report(y_dev_dbow, y_pred_dbow_svc)))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev accuracy 0.7064102564102565\n",
            "Dev F1 score:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77       509\n",
            "           1       0.57      0.63      0.60       271\n",
            "\n",
            "    accuracy                           0.71       780\n",
            "   macro avg       0.68      0.69      0.68       780\n",
            "weighted avg       0.71      0.71      0.71       780\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ2tl2GXv5Yn",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regresssion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n6AAR422kXY",
        "colab_type": "code",
        "outputId": "e803beef-cf08-4201-c809-6531fa157c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced')\n",
        "logreg.fit(X_train_dbow, y_train_dbow)\n",
        "y_pred_dbow_logreg = logreg.predict(X_dev_dbow)\n",
        "\n",
        "print('Dev accuracy %s' % accuracy_score(y_dev_dbow, y_pred_dbow_logreg))\n",
        "print('Dev classification report:\\n {}'.format(classification_report(y_dev_dbow, y_pred_dbow_logreg)))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev accuracy 0.7115384615384616\n",
            "Dev classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77       509\n",
            "           1       0.58      0.63      0.60       271\n",
            "\n",
            "    accuracy                           0.71       780\n",
            "   macro avg       0.69      0.69      0.69       780\n",
            "weighted avg       0.72      0.71      0.71       780\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}