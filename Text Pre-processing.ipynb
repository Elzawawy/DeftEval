{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_dir_path = \"deft_corpus/data/deft_files/train_converted_task1\"\n",
    "train_deft_files = os.listdir(train_dir_path)\n",
    "train_dataframe = pd.DataFrame([])\n",
    "for file in train_deft_files:\n",
    "    dataframe = pd.read_csv(os.path.join(train_dir_path, file), sep=\"\\t\", header = None)\n",
    "    dataframe.columns = [\"Sentence\",\"HasDef\"]\n",
    "    train_dataframe = train_dataframe.append(dataframe, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12143\n",
       "1     6014\n",
       "Name: HasDef, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe[\"HasDef\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe[\"parsed\"] = train_dataframe.Sentence.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'memorize fact rehearsal strategy chunk organize information manageable bit chunk Bodie Powers Fitch Hauser'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = nlp(train_dataframe[\"Sentence\"][1])\n",
    "#print ([token.text for token in test])\n",
    "#print(list(test.sents))\n",
    "' '.join([token.lemma_ for token in test if not token.is_stop and not token.is_punct and not token.is_space and token.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataframe = train_dataframe.copy()\n",
    "for index in range(len(train_dataframe)):\n",
    "    about_sentence = nlp(train_dataframe[\"Sentence\"][index])\n",
    "    processed_dataframe.iloc[index,0] = [token.lemma_ for token in about_sentence \n",
    "                                                   if not token.is_stop and not token.is_punct and \n",
    "                                                   not token.is_space and token.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technotron new technology case import good county firm industry lose money lie worker'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataframe[\"Sentence\"][10006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5246 . Because of Technotron ’s new technology — which in this case is importing goods from another county — other firms in this industry will lose money and lay off workers .'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe[\"Sentence\"][10006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "for sentence in nlp.pipe(train_dataframe['Sentence'].astype('unicode').values):\n",
    "    train_X.append(sentence.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X = np.array(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18157,)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_allowed(token):\n",
    "    '''\n",
    "        Only allow valid tokens which are not stop words\n",
    "        and punctuation symbols.\n",
    "    '''\n",
    "    if (not token or not token.string.strip() or\n",
    "        token.is_stop or token.is_punct):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def preprocess_token(token):\n",
    "    # Reduce token to its lowercase lemma form\n",
    "    return token.lemma_.strip().lower()\n",
    "\n",
    "complete_doc = \n",
    "complete_filtered_tokens = [preprocess_token(token)\n",
    "    for token in complete_doc if is_token_allowed(token)]\n",
    "complete_filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4309'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe[\"processed_tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"deft_corpus/data\"\n",
    "train_output_path = os.path.join(corpus_path, \"deft_files/converted_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(train_output_path)):\n",
    "    os.mkdir(train_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.data_loader import DeftCorpusLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DeftCorpusLoader(\"deft_corpus/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.convert_to_classification_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe, dev_dataframe = loader.load_classification_data(\"deft_corpus/data/deft_files/converted_train\", \"deft_corpus/data/deft_files/converted_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our tokens object, which is used to create documents with linguistic annotations.\n",
    "    tokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    # Removing stop words, punctations, spaces and non alphanumeric characters.\n",
    "    tokens = [ token.lemma_.lower().strip() for token in tokens \n",
    "                if not token.is_stop and not token.is_punct and \n",
    "                    not token.is_space and token.is_alpha ]\n",
    "    \n",
    "    # return preprocessed list of tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe[\"Parsed\"] = train_dataframe.Sentence.apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>HasDef</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3918 . You may recall that 6 x 6 = 36 , 6 x 7...</td>\n",
       "      <td>0</td>\n",
       "      <td>[recall, x, x, x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Memorizing these facts is rehearsal . Another...</td>\n",
       "      <td>1</td>\n",
       "      <td>[memorizing, fact, rehearsal, strategy, chunk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chunking is useful when trying to remember in...</td>\n",
       "      <td>0</td>\n",
       "      <td>[chunking, useful, try, remember, information,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3921 . Use elaborative rehearsal : In a famou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[use, elaborative, rehearsal, famous, article,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Their theory is called levels of processing .</td>\n",
       "      <td>0</td>\n",
       "      <td>[theory, call, level, process]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>The term culture refers to all of the beliefs...</td>\n",
       "      <td>1</td>\n",
       "      <td>[term, culture, refer, belief, custom, art, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18153</th>\n",
       "      <td>Culture is transmitted to people through lang...</td>\n",
       "      <td>0</td>\n",
       "      <td>[culture, transmit, people, language, model, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18154</th>\n",
       "      <td>4306 . Another method for assessment of perso...</td>\n",
       "      <td>0</td>\n",
       "      <td>[method, assessment, personality, projective, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18155</th>\n",
       "      <td>This kind of test relies on one of the defens...</td>\n",
       "      <td>1</td>\n",
       "      <td>[kind, test, rely, defense, mechanism, propose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18156</th>\n",
       "      <td>4309 . A third projective test is the Rotter ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[projective, test, rotter, incomplete, sentenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  HasDef  \\\n",
       "0       3918 . You may recall that 6 x 6 = 36 , 6 x 7...       0   \n",
       "1       Memorizing these facts is rehearsal . Another...       1   \n",
       "2       Chunking is useful when trying to remember in...       0   \n",
       "3       3921 . Use elaborative rehearsal : In a famou...       1   \n",
       "4          Their theory is called levels of processing .       0   \n",
       "...                                                  ...     ...   \n",
       "18152   The term culture refers to all of the beliefs...       1   \n",
       "18153   Culture is transmitted to people through lang...       0   \n",
       "18154   4306 . Another method for assessment of perso...       0   \n",
       "18155   This kind of test relies on one of the defens...       1   \n",
       "18156   4309 . A third projective test is the Rotter ...       0   \n",
       "\n",
       "                                                  parsed  \n",
       "0                                      [recall, x, x, x]  \n",
       "1      [memorizing, fact, rehearsal, strategy, chunk,...  \n",
       "2      [chunking, useful, try, remember, information,...  \n",
       "3      [use, elaborative, rehearsal, famous, article,...  \n",
       "4                         [theory, call, level, process]  \n",
       "...                                                  ...  \n",
       "18152  [term, culture, refer, belief, custom, art, tr...  \n",
       "18153  [culture, transmit, people, language, model, c...  \n",
       "18154  [method, assessment, personality, projective, ...  \n",
       "18155  [kind, test, rely, defense, mechanism, propose...  \n",
       "18156  [projective, test, rotter, incomplete, sentenc...  \n",
       "\n",
       "[18157 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
